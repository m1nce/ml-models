{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j4zcwLIJuG1O"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KDABJK5kuG1R"
   },
   "source": [
    "# Naive Bayes Classifier \n",
    "It is a conditional probability model, with formula: <br>\n",
    "$ P(C| x_1, x_2, x_3, ...) = \\frac{P(C)P(X|C)}{P(X)}$ <br>\n",
    "It is naive because we have naive assumption such that every pair of features are independent from each other given C.<br>\n",
    "So we can rewrite the formula as: <br>\n",
    "$ P(C| x_1, x_2, x_3, ...) = P(C)P(x_1|C)P(x_2|C)... = P(C)\\prod^{n}_{i=1} P(x_i|C)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_JUB-OvnuG1S"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Naive Bayes classifer\n",
    "By: Minchan Kim\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class Naive_Bayes():\n",
    "    \"\"\"\n",
    "    Naive Bayes classifer\n",
    "    \n",
    "    Attributes:\n",
    "        prior: P(Y)\n",
    "        likelihood: P(X_j | Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "            Some initializations, if neccesary\n",
    "        \"\"\"\n",
    "        self.model_name = 'Naive Bayes'\n",
    "    \n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\" \n",
    "            The fit function fits the Naive Bayes model based on the training data. \n",
    "            Here, we assume that all the features are **discrete** features. \n",
    "            \n",
    "            X_train is a matrix or 2-D numpy array, representing training instances. \n",
    "            Each training instance is a feature vector. \n",
    "\n",
    "            y_train contains the corresponding labels. There might be multiple (i.e., > 2) classes.\n",
    "        \"\"\"\n",
    "        # Compute the prior distribution of all y labels\n",
    "        self.prior = dict()\n",
    "        for y in y_train:\n",
    "            prior_key = f'Y = {y}'\n",
    "            if prior_key in self.prior.keys():\n",
    "                self.prior[prior_key] += 1\n",
    "            else:\n",
    "                self.prior[prior_key] = 1\n",
    "\n",
    "        # Normalize the prior distribution\n",
    "        for key in self.prior.keys():\n",
    "            self.prior[key] /= len(y_train)\n",
    "\n",
    "        # Compute the likelihood distribution of all X_j given Y\n",
    "        self.likelihood = dict()\n",
    "        for x, y in zip(np.array(X_train), y_train):\n",
    "            for j in range(len(x)):\n",
    "                likelihood_key = f'X{j} = {x[j]} | Y = {y}'\n",
    "                if likelihood_key in self.likelihood.keys():\n",
    "                    self.likelihood[likelihood_key] += 1\n",
    "                else:\n",
    "                    self.likelihood[likelihood_key] = 1\n",
    "\n",
    "        # Normalize the likelihood distribution\n",
    "        for key in self.likelihood.keys():\n",
    "            self.likelihood[key] /= len(y_train)\n",
    "        \n",
    "        \n",
    "    def ind_predict(self, x : list):\n",
    "        \"\"\" \n",
    "            Predict the most likely class label of one test instance based on its feature vector x.\n",
    "        \"\"\"\n",
    "        best_label, best_prob = None, float('-inf')\n",
    "    \n",
    "        # Iterate through each class to compute its posterior probability\n",
    "        for y, prior_count in self.prior.items():\n",
    "            cur_prob = prior_count\n",
    "            \n",
    "            # Product sum likelihoods for each feature given the class\n",
    "            for j, feature_value in enumerate(x):\n",
    "                likelihood_key = f'X{j} = {feature_value} | {y}'\n",
    "                if likelihood_key in self.likelihood:\n",
    "                    cur_prob *= self.likelihood[likelihood_key]\n",
    "                else:\n",
    "                    # Handle unknown feature values - Assume very small probability\n",
    "                    cur_prob *= 10^-9\n",
    "                    \n",
    "            if cur_prob > best_prob:\n",
    "                best_prob = cur_prob\n",
    "                best_label = y\n",
    "        \n",
    "        return best_label[-1]\n",
    "        \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "            X is a matrix or 2-D numpy array, represnting testing instances. \n",
    "            Each testing instance is a feature vector. \n",
    "            \n",
    "            Return the predictions of all instances in a list.\n",
    "        \"\"\"\n",
    "        return [self.ind_predict(x) for x in np.array(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0g4b0OM7uG1U"
   },
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/balance-scale/balance-scale.data'\n",
    "col = ['class_name','left_weight','left_distance','right_weight','right_distance']\n",
    "data = pd.read_csv(url, delimiter = ',', names = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hq7_a9C0uG1W",
    "outputId": "9f21f418-fa7d-4a77-dfc0-186ec3424e61"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_name</th>\n",
       "      <th>left_weight</th>\n",
       "      <th>left_distance</th>\n",
       "      <th>right_weight</th>\n",
       "      <th>right_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>L</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>L</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>L</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>L</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>B</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>625 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    class_name  left_weight  left_distance  right_weight  right_distance\n",
       "0            B            1              1             1               1\n",
       "1            R            1              1             1               2\n",
       "2            R            1              1             1               3\n",
       "3            R            1              1             1               4\n",
       "4            R            1              1             1               5\n",
       "..         ...          ...            ...           ...             ...\n",
       "620          L            5              5             5               1\n",
       "621          L            5              5             5               2\n",
       "622          L            5              5             5               3\n",
       "623          L            5              5             5               4\n",
       "624          B            5              5             5               5\n",
       "\n",
       "[625 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZAsYzCPzuG1Z",
    "outputId": "60ec9f98-d513-479d-a6cf-e65d50d2d3c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R    288\n",
       "L    288\n",
       "B     49\n",
       "Name: class_name, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.class_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0JjkLsxGuG1e"
   },
   "outputs": [],
   "source": [
    "X = np.matrix(data.iloc[:,1:])\n",
    "y = data.class_name\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,random_state = 88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 5, 2, 5],\n",
       "        [1, 3, 5, 1],\n",
       "        [3, 5, 1, 3],\n",
       "        ...,\n",
       "        [3, 5, 3, 3],\n",
       "        [4, 3, 2, 4],\n",
       "        [3, 2, 3, 4]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 5, 2, 5],\n",
       "        [1, 3, 5, 1],\n",
       "        [3, 5, 1, 3],\n",
       "        ...,\n",
       "        [3, 5, 3, 3],\n",
       "        [4, 3, 2, 4],\n",
       "        [3, 2, 3, 4]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZxU7v9SxuG1f"
   },
   "outputs": [],
   "source": [
    "clf = Naive_Bayes()\n",
    "clf.fit(X_train, y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_hat = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y2RZ2jYsuG1h"
   },
   "source": [
    "Overall Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MpfumdTCuG1i",
    "outputId": "6925cbf8-873b-49f0-80b2-754f569c3f8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8260869565217391"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_hat == y_test)/ 207  # you should get something like 0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HAUQN8uFuG1l",
    "outputId": "5039b87d-c601-4a6f-9310-caf7e9283c5c"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "y_pred = GaussianNB().fit(np.array(X_train), y_train).predict(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.893719806763285"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred == y_test)/ 207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = R',\n",
       " 'Y = L',\n",
       " 'Y = R',\n",
       " 'Y = L']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = dict()\n",
    "for y in y_train:\n",
    "    prior_key = f'Y = {y}'\n",
    "    if prior_key in prior:\n",
    "        prior[prior_key] += 1\n",
    "    else:\n",
    "        prior[prior_key] = 1\n",
    "\n",
    "for key in prior.keys():\n",
    "    prior[key] /= len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = dict()\n",
    "for x, y in zip(np.array(X_train), y_train):\n",
    "    for j in range(len(x)):\n",
    "        likelihood_key = f'X{j} = {x[j]} | Y = {y}'\n",
    "        if likelihood_key in likelihood:\n",
    "            likelihood[likelihood_key] += 1\n",
    "        else:\n",
    "            likelihood[likelihood_key] = 1\n",
    "\n",
    "# Normalize the likelihood distribution\n",
    "for key in likelihood.keys():\n",
    "    likelihood[key] /= len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [x for x in np.array(X_test)][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0 = 4 | Y = B\n",
      "X1 = 1 | Y = B\n",
      "X2 = 3 | Y = B\n",
      "X3 = 2 | Y = B\n"
     ]
    }
   ],
   "source": [
    "for j, feature_value in enumerate(c):\n",
    "    likelihood_key = f'X{j} = {feature_value} | {y}'\n",
    "    print(likelihood_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44019138755980863\n",
      "2.2856373647688273e-05\n",
      "0.48325358851674644\n",
      "1.2615400295386861e-05\n",
      "0.07655502392344497\n",
      "5.898015191780026e-09\n",
      "Y = R\n"
     ]
    }
   ],
   "source": [
    "best_label, best_log_prob = None, float('-inf')\n",
    "for y, prior_count in prior.items():\n",
    "    log_prob = prior_count\n",
    "    print(log_prob)\n",
    "    for j, feature_value in enumerate(c):\n",
    "        likelihood_key = f'X{j} = {feature_value} | {y}'\n",
    "        if likelihood_key in likelihood:\n",
    "            log_prob *= likelihood[likelihood_key]\n",
    "        else:  \n",
    "            log_prob *= 10^-9\n",
    "    print(log_prob)\n",
    "    if log_prob > best_log_prob:\n",
    "        best_log_prob = log_prob\n",
    "        best_label = y\n",
    "print(best_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "New_Naive_Bayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
